\section{\uppercase{BPMax ALGORITHM}}
In a nutshell, BPMax produces a four-dimensional triangular table which can be viewed as a triangular collection of triangles based on two input sequences. It considers intermolecular and intramolecular base pairings and does not allow pseudo-knots or crossings.
\begin{figure}[htbp]
\centerline{\includegraphics[scale=.9]{bpmax.png}}
\caption{The four cases defining table $F$}
\label{fig:bpm_eddy_rivas}
\end{figure}
 Figure~\ref{fig:bpm_eddy_rivas} shows the main cases for computing the $F$-table using Eddy-Rivas diagram. Equation~\ref{eqn:bpm_recurrence},   Equation~\ref{eqn:bpm_recurrence_h} and Equation~\ref{eqn:bpm_recurrence_h_dmaxp1}
show the complete recurrence equation of BPMax. Please refer to \cite{EbrahimpourBoroojeny2019} for more details about the algorithm.The double max-plus operation marked in the   
\begin{equation}
\label{eqn:bpm_recurrence}
F_{i_{1},j_{1}, i_{2}, j_{2}}  =max \left \{\begin{array}{lr}
                 S_{i_{2}, j_{2}}^{(2)}   \hspace{10pt} j_{1}\le i_{1} \\
                 \\
                 S_{i_{1}, j_{1}}^{(1)}   \hspace{10pt} j_{2}\le i_{2} \\
                 \\
                 \text{iscore}(i_{1}, i_{2})   \hspace{20pt}  i_{1} = j_{1} \text{ and }  i_{2} = j_{2} \\
                 \\
                 \max[ \colorboxed{brown}{F_{i_{1}+1, j_{1}-1, i_{2}, j_{2}}} + \text{score}(i_{1}, j_{1}), \\
                      \colorboxed{gray}{F_{i_{1}, j_{1}, i_{2}+1, j_{2}-1}} + \text{score}(i_{2}, j_{2}), \\
                      H_{i_{1},j_{1},i_{2},j_{2}}]   \hspace{30pt}  otherwise
               \end{array}
           \right. \\
\end{equation}
\begin{equation}
\label{eqn:bpm_recurrence_h}
H_{i_{1},j_{1},i_{2},j_{2}} \\ = \max \left \{\begin{array}{lr}
                 S^{(1)}(i_{1}, j_{1})  + S^{(2)}(i_{2}, j_{2}), \\
                 \\
                \\D_{i_{1},j_{1},i_{2},j_{2}}\\
                 \\
                 \colorboxed{green}{\max\limits_{k_{2}=i_{2}}^{j_{2}-1} S^{(2)}(i_{2}, k_{2}) + F_{i_{1},j_{1}, k_{2}+1, j_{2}}}\\
                 \\
                 \colorboxed{orange}{{\max\limits_{k_{2}=i_{2}}^{j_{2}-1} F_{i_{1},j_{1}, i_{2}, k_{2}} + S^{(2)}(k_{2}+1, j_{2})}}\\
                 \\
                 \colorboxed{violet}{\max\limits_{k_{1}=i_{1}}^{j_{1}-1}  S^{(1)}(i_{1}, k_{1}) + F_{k_{1}+1,j_{1},i_{2}, j_{2}}}\\
                 \\
                 \colorboxed{yellow}{\max\limits_{k_{1}=i_{1}}^{j_{1}-1} F_{i_{1},k_{1}, i_{2}, j_{2}}+ S^{(1)}(k_{1}+1, j{1})} \\
               \end{array}
           \right. \\
\end{equation}
\begin{equation}
\label{eqn:bpm_recurrence_h_dmaxp1}
D_{i_{1},j_{1},i_{2},j_{2}} \\ = 
                 \colorboxed{blue}{\max\limits_{k_{1}=i_{1}}^{j_{1}-1} \max\limits_{k_{2}=i_{2}}^{j_{2}-1} F_{i_{1},k_{1}, i_{2}, k_{2}}+ F_{k_{1}+1,j_{1}, k_{2}+1, j_{2}}}\\
\end{equation}
    blue color is the most compute-intensive portion of the algorithm. We use the same colors to highlight the dependence pattern in section \ref{section:methods}.

\section{\uppercase{Polyhedral Model}}
%\Todo{Please use articles correct: "The" Polyhedral model is a mathematical ... etc.}
The Polyhedral mModel~\cite{sanjay-fst-tcs, quinton-jvsp89, feautrier91, feautrier92a, feautrier92b} is a mathematical framework for automatic optimization and parallelization of affine programs. Polyhedron is the intersection of finitely many half spaces. It can be bounded (polytope) or unbounded. Static control parts like variables, iteration space (loop nests), dependencies can be represented using polyhedra. 
\begin{lstlisting}[label={listing:scan}, language=Caml, caption={Prefix sum}]
    for(int i=0;i<7;i++ ) {
        sum[i]=0;
        for (int j=0 ; j<=i;  j++) 
            sum[i] += array[j]; 
    }
\end{lstlisting}

%\Todo{Please don't use apostrophes for contraction: don't should be do not, Let's should eb Let us, etc.}
Let us consider the prefix sum code highlighted in Listing~\ref{listing:scan}   that computes prefix sum of an array of size $7$. The iteration space for this computation can be represented using the intersection of the finite half spaces or set of inequalities such as $j \leq i$,  $i \leq 6$  and $j = 0$ .  The points in the iteration spaces are marked as the dots and can be described by the polyhedron with vertices - $(0, 0), (0, 6)$ and $(6, 0)$.
\begin{figure}[htbp]
\begin{adjustbox}{varwidth=\textwidth,margin=0 {\abovecaptionskip} 0 0, frame=0.00pt}
\centerline{\includegraphics[scale=.48]{iteration_space.png}}
\end{adjustbox}
\caption{Polyhedral iteration space for prefix-sum}
\label{fig}
\end{figure}
%\Todo{Please also describe the data space, and explain that it is usually one or more dimension less than the iteration space.  As a result, the read and write functions are many-to-one mappings from iteration to data.  They are affine and this leads to clean closure properties of the model under program transformation.}
The data space is usually one or more dimension less than the iteration space. As a result, the data access functions are many-to-one mappings from iteration to data space. However, they are affine in nature and this leads to clean closure properties of the model under program transformation. 

Going back to the original equation, a concise way to look at this computation would be to view it as an equation $\displaystyle sum[i] = \sum_{j=0}^{i}array[j]$.  The idea behind polyhedral tool like \alphaz\ is exactly the reverse. It allows user to express one or more system of affine recurrence equations as program, transform them using the polyhedral transformations that reduces the complexity of the program, use better processor and memory allocation and then produce code for a language of interest.

\section{\uppercase{ALPHAZ}}
 \alfa\ is a strongly typed functional language which allows user to express program using polyhedral representation. It is an equational programming language that works on a system of affine recurrence equations which are defined over polyhedral domains. It was originally defined by Maurus~\cite{Mauras1989} as part of his doctoral dissertation, and subsequently extended to include subsystems and reductions~\cite{leverge-thesis, leverge-parle92, fdupont-asap96, florent-thesis, DupontQuRi93}.  Feautrier~\cite{feautrier91} showed that a polyhedral segment of code like that shown in 
 Listing~\ref{listing:scan} can be translated to an \alfa\ program, \alfa\ is richer, mathematically cleaner, and more natural, especially, but not exclusively due to reductions.  \alphaz\ allows program transformations and user directed compilation of \alfa\ programs.  It provides general framework for analysis, transformation and code generation in polyhedral equational model.  \alphaz\ is similar to an earlier tool \textsc{\texttt{MMAlpha}} which primarily targets field programmable gate array (FPGA) based hardware design~\cite{guillou-mma} but targets code generation for multi-processor shared memory programs.  Another important aspect of \alphaz\ is that it focuses on programs with reduction operations. 

Every  \alfa\ program has two pieces – system definition and compilation script.  System definition of an  \alfa\ program allows user to express input and output of the program using polyhedral domains. 
The system definition also allows programmer to express the computation in terms of equations. The program containing the system definition is called alphabets. The second piece is the compilation script that contains commands to parse the input specification, transform the program based on the user input and finally generate the code. This is where the user intervention comes into play. Algorithm~\ref{algo:matrix_mul_alphabets} highlights the alphabets program for matrix multiplication. Algorithm~\ref{algo:matrix_mul_script} presents a compiling script for matrix multiplication.
\subsection{Program Parsing}
The very first step is to read the alphabets program. This decomposes the equations into abstract syntax tree notation internally and sets up the stage for various program transformation.
\begin{algorithm}
\caption{Matrix Multiplication in Alphabets}
\begin{algorithmic} [1]
\STATE \textbf{affine} MM $\lbrace N,K,M \mid (M, N, K)  > 0  \rbrace$
\STATE \textbf{input}
\STATE  \hspace{10pt} float A $\lbrace i, j \mid 0 \leq i < M \hspace{2pt} \&\& \hspace{2pt} 0 \leq j < K   \rbrace$ ;
\STATE  \hspace{10pt} float B $\lbrace i, j \mid 0 \leq i < K \hspace{2pt} \&\& \hspace{2pt} 0 \leq j < N   \rbrace$ ;
\STATE \textbf{output}
\STATE  \hspace{10pt} float C $\lbrace i, j \mid 0 \leq i < M \hspace{2pt} \&\& \hspace{2pt} 0 \leq j < N   \rbrace$;
\STATE \textbf{local}
\STATE \hspace{10pt} \slash \slash \text{local variables}
\STATE \textbf{output}
\STATE \hspace{10pt} C[$i,j$] = reduce(+, \hspace{2pt} [$k$], \hspace{2pt} A[$i,k$] * B[$k,j$]);
\end{algorithmic}
\label{algo:matrix_mul_alphabets}
\end{algorithm}
\subsection{Program Transformation}
All transformations in \alphaz\ are semantic preserving. However, it is the responsibility of the user to ensure the transformations are valid. \textit{Normalize} is the most basic transformation. It normalizes expression into normal form as per definition and makes the program easier to read and understand. \textit{NormalizeReduction} transforms unnormalized form to normalize form. Normal form of a reduction transforms the reduce expression to be a direct child of an equation.  \textit{setSpaceTimeMap} allows user to specify schedule and processor allocation to specify the order in which the iteration space is visited by one or more processors. System with multiple variables requires dimension of all the space time maps to be equal.
 \begin{algorithm}
 \caption{Matrix Multiplication Command Script}
 \begin{algorithmic} [1]
 \STATE \text{\slash \slash \hspace{2pt}$Step-1: Parse \hspace{2pt} Alphabet \hspace{2pt} $}
 \STATE \text{prog=ReadAlphabets("MM.ab");}
 \STATE \text{system = “MM”;}
 \STATE \text{outDir="./src";}

 \STATE \text{}
 \STATE \text{\slash \slash \hspace{2pt}$Step-2: Perform \hspace{2pt} polyhedral \hspace{2pt}  transformation$}
 \STATE \text{Normalize(prog);}
 \STATE \text{setSpaceTimeMap(prog,  system,  “C”,  }
 \STATE \text{\hspace{140pt}"($i,j,k \mapsto i, k, j$)”,}
 \STATE \text{\hspace{140pt}“($i,j \mapsto i, -1, j$)”);}
 \STATE \text{setParallel(prog,  system,  “”,  "0" );}
 \STATE \text{}
 \STATE \text{\slash \slash \hspace{2pt}$Step-3: Generate  \hspace{2pt} code$}
 \STATE \text{generateWriteC(prog,  system,  outDir);}
\STATE \text{generateScheduleC(prog,  system,  outDir);}
\end{algorithmic}
\label{algo:matrix_mul_script}
\end{algorithm}
\textit{NormalizeReduction} generates additional variables associated with the reductions. Specifying schedule for such variable requires two different schedules to be provided – the first one specifies the order in which the iteration space will be visited and the other specifies the time at which the initialization should occur before starting the reduction. This also has dependency on the schedule. \textit{setMemoryMap} - Memory map is a mapping between iteration points in the domain to the memory location. By default, \alphaz\ uses identity function as a memory map for each variable and bounding box of the polyhedral representation of the variable for storage. It allows multiple variables with different dimension to share same memory map based on affine function. \textit{setMemorySpace} is similar to memory map. Except that multiple variables with the same dimension can share memory space. \textit{setParallel} allows user to specify one or more dimensions of the schedule to be executed in parallel by different cores. User can also specify predicate as an ordering dimension to identify the loop dimension to be marked as parallel. Tiling transformation allows user to chop the iteration space to improve data locality and parallelization granularity. 
\subsection{Code generation}
These set of the commands produce target code (e.g. c) based on the program transformation and expected to be invoked after applying all the desired transformations. \alphaz\ has various code generation options like – \textit{generateWriteC} which is sequential in nature and useful to check the correctness of the program, schedule code generation – \textit{generateScheduleC}. Sequential code generation hardly requires any program transformation. However, efficient schedule code generation depends on the choice of various transformations specially the target mapping related transformations. The tiling transformation is not applied upfront rather invoked as part of
\begin{lstlisting}[language=Caml, caption=Generated code - Matrix multiplication]
    #define S1(i,j,i2) C(i,i2) = 0.0
    #define S0(i0,i1,i2) C(i0,i2) = (C(i0,i2))+((A(i0,i1))*(B(i1,i2)))
    {
        int c1,c2,c3;
        #pragma omp parallel for private(c2,c3)
        for(c1=0;c1 <= M-1;c1+=1){
	        for(c3=0;c3 <= N-1;c3+=1){
	            S1((c1),(-1),(c3));
	        }
            for(c2=0;c2 <= K-1;c2+=1){
                for(c3=0;c3 <= N-1;c3+=1){
                    S0((c1),(c2),(c3));
                }
            }
        }
    }
\end{lstlisting}
the post processing phase of the schedule code generation. Please refer to Kim et al. \cite{Kim2010} for more details on tiling code generation algorithm.

%\Comment{Haven't read beyond this}